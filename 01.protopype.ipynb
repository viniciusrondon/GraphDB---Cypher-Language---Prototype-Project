{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "76ab89a9",
   "metadata": {},
   "source": [
    "# Q&A Agent With Graph DB\n",
    "\n",
    "Building a Question and Answering application over a Graph Database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ccc490",
   "metadata": {},
   "source": [
    "# Setup "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c7452f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "## Openai\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "\n",
    "# Nvidia\n",
    "os.environ[\"NVIDIA_API_KEY\"] = os.getenv(\"NVIDIA_API_KEY\")\n",
    "\n",
    "## langsmith tracking\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = os.getenv(\"LANGCHAIN_PROJECT\")\n",
    "\n",
    "## Huggingface\n",
    "os.environ[\"HF_TOKEN\"] = os.getenv(\"HF_TOKEN\")\n",
    "\n",
    "## Neo4j\n",
    "os.environ[\"NEO4J_URI\"] = os.getenv(\"NEO4J_URI\")\n",
    "os.environ[\"NEO4J_USERNAME\"] = os.getenv(\"NEO4J_USERNAME\")\n",
    "os.environ[\"NEO4J_PASSWORD\"] = os.getenv(\"NEO4J_PASSWORD\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "14eb5a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.graphs import Neo4jGraph\n",
    "\n",
    "graph = Neo4jGraph(\n",
    "    url=os.environ[\"NEO4J_URI\"],\n",
    "    username=os.environ[\"NEO4J_USERNAME\"],\n",
    "    password=os.environ[\"NEO4J_PASSWORD\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13750a2",
   "metadata": {},
   "source": [
    "## Import dataset\n",
    "\n",
    "I woul like to cite and thanks [Tomaz Bratanic](https://github.com/tomasonjo) -- Graph ML and GenAI research at Neo4j -- to provide your public [datasets](https://github.com/tomasonjo/blog-datasets)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b8f12024",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dataset Movie reviews\n",
    "\n",
    "movie_query = \"\"\"\n",
    "LOAD CSV WITH HEADERS FROM 'https://raw.githubusercontent.com/tomasonjo/blog-datasets/main/movies/movies_small.csv' AS row\n",
    "\n",
    "MERGE (m:Movie{movieId: toInteger(row.movieId)})\n",
    "SET m.title = row.title,\n",
    "    m.release = datetime(row.release),\n",
    "    m.imdbRating = toFloat(row.imdbRating)\n",
    "\n",
    "FOREACH (director IN split(row.director, '|') |\n",
    "    MERGE (d:Director{name: trim(director)})\n",
    "    MERGE (m)-[:DIRECTED_BY]->(d)\n",
    "    MERGE (d)-[:DIRECTOR_OF]->(m)\n",
    ")\n",
    "\n",
    "FOREACH (actor IN split(row.actors, '|') |\n",
    "    MERGE (a:Actor{name: trim(actor)})\n",
    "    MERGE (a)-[:ACTOR_OF]->(m)\n",
    "    MERGE (m)-[:HAS_ACTOR]->(a)\n",
    ")\n",
    "\n",
    "FOREACH (genre IN split(row.genres, '|') |\n",
    "    MERGE (g:Genre{name: trim(genre)})\n",
    "    MERGE (m)-[:HAS_GENRE]->(g)\n",
    "    MERGE (g)-[:GENRE_OF]->(m)\n",
    ")\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b5bf263e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to read from defunct connection IPv4Address(('si-01de3140-caed.production-orch-0696.neo4j.io', 7687)) (ResolvedIPv4Address(('34.28.184.63', 7687)))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.query(movie_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "721ffd9c",
   "metadata": {},
   "source": [
    "#### 📊 **Gaph Relatioship Illustration of `ACTOR_OF`:**\n",
    "\n",
    "![Relação ACTOR_OF](image/actor_of.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d126a56d",
   "metadata": {},
   "source": [
    "#### 📊 **Gaph Relatioship Illustration of `HAS_GENRE`:**\n",
    "\n",
    "![Relação ACTOR_OF](image/genre.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "642c3fa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to read from defunct connection IPv4Address(('si-01de3140-caed.production-orch-0696.neo4j.io', 7687)) (ResolvedIPv4Address(('34.28.184.63', 7687)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node properties:\n",
      "CEO {name: STRING, POB: STRING, YOB: INTEGER}\n",
      "Company {name: STRING}\n",
      "User {name: STRING, city: STRING, userId: INTEGER, age: INTEGER}\n",
      "Post {userId: INTEGER}\n",
      "Movie {movieId: INTEGER, title: STRING, imdbRating: FLOAT}\n",
      "Director {name: STRING}\n",
      "Actor {name: STRING}\n",
      "Genre {name: STRING}\n",
      "Relationship properties:\n",
      "\n",
      "The relationships:\n",
      "(:CEO)-[:CEO]->(:Company)\n",
      "(:User)-[:POSTED]->(:Post)\n",
      "(:User)-[:FRIEND]->(:User)\n",
      "(:User)-[:LIKES]->(:User)\n",
      "(:Movie)-[:DIRECTED_BY]->(:Director)\n",
      "(:Movie)-[:HAS_ACTOR]->(:Actor)\n",
      "(:Movie)-[:HAS_GENRE]->(:Genre)\n",
      "(:Director)-[:DIRECTOR_OF]->(:Movie)\n",
      "(:Actor)-[:ACTOR_OF]->(:Movie)\n",
      "(:Genre)-[:GENRE_OF]->(:Movie)\n"
     ]
    }
   ],
   "source": [
    "graph.refresh_schema()\n",
    "print(graph.schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c4dbed",
   "metadata": {},
   "source": [
    "### [Langchain Cypher Query framework](https://python.langchain.com/docs/integrations/graphs/neo4j_cypher/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2319dd1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from langchain_groq import ChatGroq\n",
    "\n",
    "#llm = ChatGroq(model_name=\"llama3-8b-8192\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5049f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9009795e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GraphCypherQAChain(verbose=True, graph=<langchain_community.graphs.neo4j_graph.Neo4jGraph object at 0x7de4dadbfbb0>, cypher_generation_chain=LLMChain(prompt=PromptTemplate(input_variables=['question', 'schema'], template='Task:Generate Cypher statement to query a graph database.\\nInstructions:\\nUse only the provided relationship types and properties in the schema.\\nDo not use any other relationship types or properties that are not provided.\\nSchema:\\n{schema}\\nNote: Do not include any explanations or apologies in your responses.\\nDo not respond to any questions that might ask anything else than for you to construct a Cypher statement.\\nDo not include any text except the generated Cypher statement.\\n\\nThe question is:\\n{question}'), llm=ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x7de493edbc40>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x7de493d2a9e0>, root_client=<openai.OpenAI object at 0x7de493d287f0>, root_async_client=<openai.AsyncOpenAI object at 0x7de493edb400>, model_name='gpt-4.1-nano', temperature=0.0, openai_api_key=SecretStr('**********'), openai_proxy='')), qa_chain=ChatPromptTemplate(input_variables=['function_response', 'question'], input_types={'function_response': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]]}, messages=[SystemMessage(content=\"You are an assistant that helps to form nice and human \\nunderstandable answers based on the provided information from tools.\\nDo not add any other information that wasn't present in the tools, and use \\nvery concise style in interpreting results!\\n\"), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['question'], template='{question}')), MessagesPlaceholder(variable_name='function_response')])\n",
       "| ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x7de493edbc40>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x7de493d2a9e0>, root_client=<openai.OpenAI object at 0x7de493d287f0>, root_async_client=<openai.AsyncOpenAI object at 0x7de493edb400>, model_name='gpt-4.1-nano', temperature=0.0, openai_api_key=SecretStr('**********'), openai_proxy='')\n",
       "| StrOutputParser(), graph_schema='Node properties are the following:\\nCEO {name: STRING, POB: STRING, YOB: INTEGER},Company {name: STRING},User {name: STRING, city: STRING, userId: INTEGER, age: INTEGER},Post {userId: INTEGER},Movie {movieId: INTEGER, title: STRING, imdbRating: FLOAT},Director {name: STRING},Actor {name: STRING},Genre {name: STRING}\\nRelationship properties are the following:\\n\\nThe relationships are the following:\\n(:CEO)-[:CEO]->(:Company),(:User)-[:POSTED]->(:Post),(:User)-[:FRIEND]->(:User),(:User)-[:LIKES]->(:User),(:Movie)-[:DIRECTED_BY]->(:Director),(:Movie)-[:HAS_ACTOR]->(:Actor),(:Movie)-[:HAS_GENRE]->(:Genre),(:Director)-[:DIRECTOR_OF]->(:Movie),(:Actor)-[:ACTOR_OF]->(:Movie),(:Genre)-[:GENRE_OF]->(:Movie)', top_k=3, return_intermediate_steps=True, use_function_response=True, allow_dangerous_requests=True)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import GraphCypherQAChain\n",
    "\n",
    "chain = GraphCypherQAChain.from_llm(\n",
    "    llm=llm, \n",
    "    graph=graph, \n",
    "    top_k=3, \n",
    "    verbose=True,\n",
    "    allow_dangerous_requests=True, \n",
    "    return_intermediate_steps=True,\n",
    "    use_function_response=True,  # This parameter passes results as function output, very important\n",
    ")\n",
    "\n",
    "chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "01f38c4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error in StdOutCallbackHandler.on_chain_start callback: AttributeError(\"'NoneType' object has no attribute 'get'\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Cypher:\n",
      "\u001b[32;1m\u001b[1;3mMATCH (d:Director {name: 'Christopher Nolan'})-[:DIRECTOR_OF]->(m:Movie)\n",
      "RETURN m.title, m.imdbRating\u001b[0m\n",
      "Full Context:\n",
      "\u001b[32;1m\u001b[1;3m[]\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'query': 'What are the movies directed by Christopher Nolan?',\n",
       " 'result': \"Sorry, I couldn't find information on movies directed by Christopher Nolan.\",\n",
       " 'intermediate_steps': [{'query': \"MATCH (d:Director {name: 'Christopher Nolan'})-[:DIRECTOR_OF]->(m:Movie)\\nRETURN m.title, m.imdbRating\"},\n",
       "  {'context': []}]}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = chain.invoke({\"query\": \"What are the movies directed by Christopher Nolan?\"})\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8fe3cf6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error in StdOutCallbackHandler.on_chain_start callback: AttributeError(\"'NoneType' object has no attribute 'get'\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Cypher:\n",
      "\u001b[32;1m\u001b[1;3mMATCH (d:Director {name: 'Joe Johnston'})-[:DIRECTOR_OF]->(m:Movie)\n",
      "RETURN m.title, m.imdbRating\u001b[0m\n",
      "Full Context:\n",
      "\u001b[32;1m\u001b[1;3m[{'m.title': 'Jumanji', 'm.imdbRating': 6.9}]\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'query': 'What are the movies directed by Joe Johnston?',\n",
       " 'result': 'Joe Johnston directed the movie \"Jumanji.\"',\n",
       " 'intermediate_steps': [{'query': \"MATCH (d:Director {name: 'Joe Johnston'})-[:DIRECTOR_OF]->(m:Movie)\\nRETURN m.title, m.imdbRating\"},\n",
       "  {'context': [{'m.title': 'Jumanji', 'm.imdbRating': 6.9}]}]}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = chain.invoke({\"query\": \"What are the movies directed by Joe Johnston?\"})\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78cde31c",
   "metadata": {},
   "source": [
    "`use_function_response=True` tells the chain to *trust and use the tool’s (Cypher)* response directly when forming the final answer, instead of relying on the LLM’s default “be conservative if unsure” behavior. In practice, it:\n",
    "\n",
    "- Injects the query result (rows returned by Neo4j) into the answer step in a structured way.\n",
    "\n",
    "- Reduces “I don’t know” fallbacks, because the LLM now sees a clear, machine-formatted function/tool result.\n",
    "\n",
    "- Acts similarly to return_direct=True, but still lets the LLM phrase the result in natural language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6fa44873",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error in StdOutCallbackHandler.on_chain_start callback: AttributeError(\"'NoneType' object has no attribute 'get'\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Cypher:\n",
      "\u001b[32;1m\u001b[1;3mMATCH (m:Movie)\n",
      "RETURN m.title, m.imdbRating\n",
      "ORDER BY m.imdbRating DESC\n",
      "LIMIT 10\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to read from defunct connection IPv4Address(('si-01de3140-caed.production-orch-0696.neo4j.io', 7687)) (ResolvedIPv4Address(('34.28.184.63', 7687)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Context:\n",
      "\u001b[32;1m\u001b[1;3m[{'m.title': 'Shawshank Redemption, The', 'm.imdbRating': 9.3}, {'m.title': 'Pulp Fiction', 'm.imdbRating': 8.9}, {'m.title': 'Star Wars: Episode IV - A New Hope', 'm.imdbRating': 8.7}]\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'query': 'What are the best movies ?',\n",
       " 'result': 'The best movies are \"The Shawshank Redemption\" (IMDB 9.3), \"Pulp Fiction\" (IMDB 8.9), and \"Star Wars: Episode IV - A New Hope\" (IMDB 8.7).',\n",
       " 'intermediate_steps': [{'query': 'MATCH (m:Movie)\\nRETURN m.title, m.imdbRating\\nORDER BY m.imdbRating DESC\\nLIMIT 10'},\n",
       "  {'context': [{'m.title': 'Shawshank Redemption, The', 'm.imdbRating': 9.3},\n",
       "    {'m.title': 'Pulp Fiction', 'm.imdbRating': 8.9},\n",
       "    {'m.title': 'Star Wars: Episode IV - A New Hope', 'm.imdbRating': 8.7}]}]}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = chain.invoke({\"query\": \"What are the best movies ?\"})\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "31c9174e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error in StdOutCallbackHandler.on_chain_start callback: AttributeError(\"'NoneType' object has no attribute 'get'\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔧 Creating a working chain with correct parameters...\n",
      "============================================================\n",
      "✅ Working chain created with correct qa_prompt parameter!\n",
      "\n",
      "🧪 Testing the working chain...\n",
      "Generated Cypher:\n",
      "\u001b[32;1m\u001b[1;3mMATCH (d:Director {name: 'Joe Johnston'})-[:DIRECTOR_OF]->(m:Movie)\n",
      "RETURN m.title\u001b[0m\n",
      "Full Context:\n",
      "\u001b[32;1m\u001b[1;3m[{'m.title': 'Jumanji'}]\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "✅ Query: What are the movies directed by Joe Johnston?\n",
      "✅ Answer: I don't have enough information to answer this question.\n",
      "\n",
      "🔍 Intermediate steps:\n",
      "  Generated Cypher: MATCH (d:Director {name: 'Joe Johnston'})-[:DIRECTOR_OF]->(m:Movie)\n",
      "RETURN m.title\n",
      "  Context: [{'m.title': 'Jumanji'}]\n"
     ]
    }
   ],
   "source": [
    "# Fix the GraphCypherQAChain with correct parameters\n",
    "print(\"🔧 Creating a working chain with correct parameters...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import GraphCypherQAChain\n",
    "\n",
    "# Create a custom QA prompt that explicitly tells the LLM to use the context\n",
    "custom_qa_prompt = PromptTemplate(\n",
    "    input_variables=[\"context\", \"question\"],\n",
    "    template=\"\"\"You are a helpful assistant that answers questions about movies using the provided graph database context.\n",
    "\n",
    "Context from the database: {context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "IMPORTANT: Use the information from the context above to answer the question. If the context contains relevant data, provide a clear answer based on that data. If the context is empty or doesn't contain relevant information, say \"I don't have enough information to answer this question.\"\n",
    "\n",
    "Answer:\"\"\"\n",
    ")\n",
    "\n",
    "# Create a new chain with the correct qa_prompt parameter\n",
    "working_chain = GraphCypherQAChain.from_llm(\n",
    "    llm=llm,\n",
    "    graph=graph,\n",
    "    qa_prompt=custom_qa_prompt,  # This is the correct parameter name\n",
    "    top_k=5,\n",
    "    verbose=True,\n",
    "    allow_dangerous_requests=True,\n",
    "    return_intermediate_steps=True\n",
    ")\n",
    "\n",
    "print(\"✅ Working chain created with correct qa_prompt parameter!\")\n",
    "\n",
    "# Test the working chain\n",
    "print(\"\\n🧪 Testing the working chain...\")\n",
    "test_query = \"What are the movies directed by Joe Johnston?\"\n",
    "\n",
    "try:\n",
    "    response = working_chain.invoke({\"query\": test_query})\n",
    "    print(f\"✅ Query: {test_query}\")\n",
    "    print(f\"✅ Answer: {response.get('result', 'No result')}\")\n",
    "    \n",
    "    # Show the intermediate steps\n",
    "    if 'intermediate_steps' in response:\n",
    "        print(\"\\n🔍 Intermediate steps:\")\n",
    "        for i, step in enumerate(response['intermediate_steps']):\n",
    "            if isinstance(step, dict):\n",
    "                if 'query' in step:\n",
    "                    print(f\"  Generated Cypher: {step['query']}\")\n",
    "                if 'context' in step:\n",
    "                    print(f\"  Context: {step['context']}\")\n",
    "            else:\n",
    "                print(f\"  Step {i+1}: {step}\")\n",
    "                \n",
    "except Exception as e:\n",
    "    print(f\"❌ Error: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "30f10b4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/Rondon/Documents/1. Python Starter/16.krish_IA_Udemy/15.graph_database/.venv/lib/python3.10/site-packages/pydantic/v1/main.py:725: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use RunnableSequence, e.g., `prompt | llm` instead.\n",
      "  return cls(**value_as_dict)\n",
      "Error in StdOutCallbackHandler.on_chain_start callback: AttributeError(\"'NoneType' object has no attribute 'get'\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔧 Testing use_function_response parameter...\n",
      "============================================================\n",
      "✅ Function response chain created!\n",
      "\n",
      "🧪 Testing function response chain...\n",
      "\n",
      "❓ Query: What are the movies directed by Joe Johnston?\n",
      "Generated Cypher:\n",
      "\u001b[32;1m\u001b[1;3mMATCH (d:Director {name: 'Joe Johnston'})-[:DIRECTOR_OF]->(m:Movie)\n",
      "RETURN m.title\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to read from defunct connection IPv4Address(('si-01de3140-caed.production-orch-0696.neo4j.io', 7687)) (ResolvedIPv4Address(('34.28.184.63', 7687)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Context:\n",
      "\u001b[32;1m\u001b[1;3m[{'m.title': 'Jumanji'}]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error in StdOutCallbackHandler.on_chain_start callback: AttributeError(\"'NoneType' object has no attribute 'get'\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "✅ Answer: Joe Johnston directed the movie \"Jumanji.\"\n",
      "🔍 Context used: [{'m.title': 'Jumanji'}]\n",
      "----------------------------------------\n",
      "\n",
      "❓ Query: Who directed Jumanji?\n",
      "Generated Cypher:\n",
      "\u001b[32;1m\u001b[1;3mMATCH (d:Director)-[:DIRECTOR_OF]->(m:Movie {title: 'Jumanji'}) RETURN d.name\u001b[0m\n",
      "Full Context:\n",
      "\u001b[32;1m\u001b[1;3m[{'d.name': 'Joe Johnston'}]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error in StdOutCallbackHandler.on_chain_start callback: AttributeError(\"'NoneType' object has no attribute 'get'\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "✅ Answer: Jumanji was directed by Joe Johnston.\n",
      "🔍 Context used: [{'d.name': 'Joe Johnston'}]\n",
      "----------------------------------------\n",
      "\n",
      "❓ Query: What are some action movies?\n",
      "Generated Cypher:\n",
      "\u001b[32;1m\u001b[1;3mMATCH (g:Genre {name: 'Action'})<-[:HAS_GENRE]-(m:Movie)\n",
      "RETURN m.title, m.imdbRating\u001b[0m\n",
      "Full Context:\n",
      "\u001b[32;1m\u001b[1;3m[{'m.title': 'Heat', 'm.imdbRating': 8.2}, {'m.title': 'Sudden Death', 'm.imdbRating': 5.7}, {'m.title': 'GoldenEye', 'm.imdbRating': 7.2}, {'m.title': 'Cutthroat Island', 'm.imdbRating': 5.6}, {'m.title': 'Money Train', 'm.imdbRating': 5.6}, {'m.title': 'Assassins', 'm.imdbRating': 6.3}, {'m.title': 'Dead Presidents', 'm.imdbRating': 6.8}, {'m.title': 'Mortal Kombat', 'm.imdbRating': 5.8}, {'m.title': 'Lawnmower Man 2: Beyond Cyberspace', 'm.imdbRating': 2.4}, {'m.title': 'From Dusk Till Dawn', 'm.imdbRating': 7.3}]\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "✅ Answer: Some action movies include \"Heat,\" \"Sudden Death,\" \"GoldenEye,\" \"From Dusk Till Dawn,\" and \"Assassins.\"\n",
      "🔍 Context used: [{'m.title': 'Heat', 'm.imdbRating': 8.2}, {'m.title': 'Sudden Death', 'm.imdbRating': 5.7}, {'m.title': 'GoldenEye', 'm.imdbRating': 7.2}, {'m.title': 'Cutthroat Island', 'm.imdbRating': 5.6}, {'m.title': 'Money Train', 'm.imdbRating': 5.6}, {'m.title': 'Assassins', 'm.imdbRating': 6.3}, {'m.title': 'Dead Presidents', 'm.imdbRating': 6.8}, {'m.title': 'Mortal Kombat', 'm.imdbRating': 5.8}, {'m.title': 'Lawnmower Man 2: Beyond Cyberspace', 'm.imdbRating': 2.4}, {'m.title': 'From Dusk Till Dawn', 'm.imdbRating': 7.3}]\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Alternative approach: Use use_function_response parameter\n",
    "print(\"🔧 Testing use_function_response parameter...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Create a chain with use_function_response parameter\n",
    "function_chain = GraphCypherQAChain.from_llm(\n",
    "    llm=llm,\n",
    "    graph=graph,\n",
    "    verbose=True,\n",
    "    use_function_response=True,  # This parameter passes results as function output\n",
    "    allow_dangerous_requests=True,\n",
    "    return_intermediate_steps=True\n",
    ")\n",
    "\n",
    "print(\"✅ Function response chain created!\")\n",
    "\n",
    "# Test the function response chain\n",
    "print(\"\\n🧪 Testing function response chain...\")\n",
    "test_queries = [\n",
    "    \"What are the movies directed by Joe Johnston?\",\n",
    "    \"Who directed Jumanji?\",\n",
    "    \"What are some action movies?\"\n",
    "]\n",
    "\n",
    "for query in test_queries:\n",
    "    print(f\"\\n❓ Query: {query}\")\n",
    "    try:\n",
    "        response = function_chain.invoke({\"query\": query})\n",
    "        print(f\"✅ Answer: {response.get('result', 'No result')}\")\n",
    "        \n",
    "        # Show context if available\n",
    "        if 'intermediate_steps' in response and response['intermediate_steps']:\n",
    "            for step in response['intermediate_steps']:\n",
    "                if isinstance(step, dict) and 'context' in step:\n",
    "                    context = step['context']\n",
    "                    if context:\n",
    "                        print(f\"🔍 Context used: {context}\")\n",
    "                    else:\n",
    "                        print(\"🔍 No context found\")\n",
    "                    break\n",
    "                    \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error: {str(e)}\")\n",
    "    \n",
    "    print(\"-\" * 40)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f4a0cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d88687c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2467ea74",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79513693",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e0d1dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
